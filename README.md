# 1. AlexNet CNN Architecture (Image Classification)
# âœ… Improved Code â€“ Key Points

Added Batch Normalization layers after early convolution layers

Improved training stability and convergence speed

Used explicit class initialization for better clarity

Enhanced overall model robustness without changing outputs

# ðŸ“˜ Key Points

AlexNet CNN implemented for large-scale image classification

Batch Normalization reduces internal covariate shift

Dropout layers prevent overfitting in fully connected layers

Enhancements improve training performance while preserving design

# 2. CNN using Iris Features (Image-style Classification)
## âœ… Improved Code â€“ Key Points

Converted Iris numerical features into 2Ã—2 image format

Applied feature normalization for stable CNN training

Used a lightweight CNN architecture suitable for small data

Added clear prediction output with flower class name

Displayed the feature-image with predicted class for visibility

## ðŸ“˜ Key Points

Iris dataset does not contain images; hence features were reshaped into image form

CNN was used to learn spatial relationships among features

Model classifies Iris flowers into Setosa, Versicolor, and Virginica

Approach demonstrates innovative use of CNN on tabular data

# 3. Q-Learning Path Finding on Graph (Police & Drug Traces)
## âœ… Improved Code â€“ Key Points

Fixed action selection bug in Q-learning exploration

Simplified reward matrix initialization

Removed duplicate functions and cleaned logic

Added environment-aware learning (police & drug traces)

Improved visualization of rewards and learned paths

## ðŸ“˜ Key Points

Implemented Q-learning to find optimal path in a graph

Goal node rewarded to guide learning

Environment factors like police and drug traces were incorporated

Agent learns both efficiency and safety

# 4. LSTM Time-Series Forecasting (Airline Passengers)
## âœ… Improved Code â€“ Key Points

Removed hard-coded dataset path for portability

Added reusable time-series dataset creation function

Improved visualization of predictions vs actual data

Used RMSE for proper model evaluation

## ðŸ“˜ Key Points

LSTM model predicts airline passenger traffic over time

Data normalized using Min-Max scaling

Time-step window captures temporal dependency

Results show effective learning of sequential patterns

# 5. Character-Level RNN Text Generation
## âœ… Improved Code â€“ Key Points

Clarified RNN hidden unit configuration

Removed redundant commented code

Simplified text generation logic

Added meaningful variable names and structure

Ensured consistent sequence length during prediction

## ðŸ“˜ Key Points

Character-level RNN trained on given text input

Model learns character sequence dependencies

Uses one-hot encoding for character representation

Generates new text based on learned patterns

Demonstrates sequence learning using SimpleRNN

# 6. Reinforcement Learning Tic-Tac-Toe Game
## âœ… Improved Code â€“ Key Points

Fixed syntax and player switching errors

Simplified winner detection logic

Improved reward propagation stability

Cleaned state reset and gameplay flow

Enhanced human vs AI interaction

## ðŸ“˜ Key Points

Reinforcement learning agent trained to play Tic-Tac-Toe

Agent learns optimal moves through repeated self-play

Rewards guide learning for win, loss, and draw

Trained policy stored and reused against human player

Demonstrates exploration, exploitation, and policy learning
